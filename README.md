# CargoTrackAI

CargoTrackAI is a computer vision project that demonstrates how deep
learning--based object detection can be integrated into a structured
object counting system using rule-based motion analysis.

This project covers the complete pipeline:

-   Extracting frames from video
-   Labeling images using annotation tools
-   Training a custom YOLO model via command line
-   Running inference on video using a Python script
-   Counting detected objects using motion logic

The implementation is fully done in Python.

------------------------------------------------------------------------

## ğŸ“ Project Structure

    CargoTrackAI/
    â”‚
    â”œâ”€â”€ dataset/            # Labeled dataset (images + labels)
    â”œâ”€â”€ original data/      # Raw source videos
    â”œâ”€â”€ train/              # Training configuration files
    â”œâ”€â”€ runs/detect/        # YOLO training outputs
    â”œâ”€â”€ objects/            # Extracted frames or processed images
    â”‚
    â”œâ”€â”€ extract_frames.py   # Script to extract images from video
    â”œâ”€â”€ test_model.py       # Script to run inference + counting
    â”œâ”€â”€ req.txt             # Python dependencies
    â”œâ”€â”€ README.md
    â”œâ”€â”€ LICENSE
    â””â”€â”€ .gitignore

------------------------------------------------------------------------

# ğŸš€ Workflow Overview

## 1ï¸âƒ£ Step 1 -- Extract Frames from Video

Raw videos were placed inside:

    original data/

Frames were extracted using:

``` bash
python extract_frames.py
```

This script: - Reads video using OpenCV - Extracts frames at a fixed
interval - Saves images into the dataset folder

------------------------------------------------------------------------

## 2ï¸âƒ£ Step 2 -- Image Labeling

After extracting frames, images were labeled using an annotation tool.

### Tools You Can Use

-   Roboflow (Web-based)
-   LabelImg (Desktop)
-   CVAT
-   Any YOLO-compatible labeling tool

### Label Format

Images were labeled in **YOLO format**:

    class_id x_center y_center width height

All values are normalized between 0 and 1.

The dataset folder follows this structure:

    dataset/
     â”œâ”€â”€ images/
     â”‚    â”œâ”€â”€ train/
     â”‚    â””â”€â”€ val/
     â””â”€â”€ labels/
          â”œâ”€â”€ train/
          â””â”€â”€ val/

------------------------------------------------------------------------

## 3ï¸âƒ£ Step 3 -- Model Training (Command Line)

Training was done using Ultralytics YOLO via command line.

Example training command:

``` bash
yolo detect train   model=yolov8n.pt   data=train/data.yaml   epochs=50   imgsz=640
```

After training completes, model weights are saved in:

    runs/detect/train/weights/best.pt

------------------------------------------------------------------------

## 4ï¸âƒ£ Step 4 -- Testing the Model (Manual Video Input)

Inference is performed using:

``` bash
python test_model.py
```

This script:

-   Loads the trained model
-   Accepts manual video input
-   Runs object detection
-   Tracks object movement
-   Applies rule-based counting logic
-   Displays processed video with:
    -   Bounding boxes
    -   Counting lines
    -   Live object count

------------------------------------------------------------------------

# ğŸ§  Counting Logic

The system uses two horizontal reference lines:

-   Lower line â†’ Entry zone
-   Upper line â†’ Exit zone

Counting rule:

1.  Object crosses lower line â†’ marked as inside
2.  Object crosses upper line â†’ count incremented
3.  Each object is counted only once

This prevents duplicate counting.

------------------------------------------------------------------------

# ğŸ›  Installation

### 1. Clone Repository

``` bash
git clone https://github.com/Darshan-U-P/CargoTrackAI.git
cd CargoTrackAI
```

### 2. Install Dependencies

``` bash
pip install -r req.txt
```

------------------------------------------------------------------------

# â–¶ï¸ Run Inference

``` bash
python test_model.py
```

Make sure your trained model path inside `test_model.py` is correct.

------------------------------------------------------------------------

# ğŸ“¦ Requirements

Major dependencies:

-   Python 3.9+
-   ultralytics
-   opencv-python
-   torch
-   numpy

See `req.txt` for full list.

------------------------------------------------------------------------

# ğŸ¯ Purpose

CargoTrackAI demonstrates:

-   End-to-end custom object detection training
-   Practical dataset preparation
-   Real-time video inference
-   Rule-based object counting logic
-   Structured computer vision pipeline implementation

This project is designed for learning, experimentation, and
demonstration of applied AI in monitoring systems.

------------------------------------------------------------------------

# ğŸ“œ License

This project is licensed under the MIT License.
